[[Week 9.pdf]]

What did you learn from the other student presentations on this week's topic?
* Will G
	* Further elaboration on functionalism and the hard problem of consciousness
		* Identify consciousness by its function
			* Functionalism brought in [[Every Major Theory of Consciousness Explained in 10 Minutes]]
		* Breaking down consciousness into pieces
	* Integrated Information Theory
		* An attempt to classify the properties of consciousness from the presumption that we are conscious
		* **![](https://lh7-rt.googleusercontent.com/slidesz/AGV_vUcB_Tn7dBdElegoiAt3JbPgnURgKcZq7reg3i_R6CfwDKaMHqqFkedwG5xUz_J6z_zOY8ZgLckwpTDyt4c32JdlF98i5K7g8wgpjo9Yo6JH6gBQSrEHSJ3AK0mjEAU1ebMuVcZJ=s2048?key=HUAv7i993tyJD5Ya6nycjVP_)**
		* Axioms of Experience:
			* Intrinsicality
			* Information
			* Integration
			* Exclusion
			* Composition
			* **![](https://lh7-rt.googleusercontent.com/slidesz/AGV_vUfSsc7mJx8lZnTZaREbE77-urnjxvZnp5cR8_6SQS1DxVtYBIcWo9oRTwK4P2gbh6P2NfKhBloucVW0B3xu2DG1JGwJkSJUC2qJh-DAxm5_JniYeJ13TU1wm8WGduAYl4Ht534qFA=s2048?key=HUAv7i993tyJD5Ya6nycjVP_)**
	* Models of Mathematical Consciousness
		* **![](https://lh7-rt.googleusercontent.com/slidesz/AGV_vUf6EvDo1lgWDc0-y02mvb0kas1bEQy1QUInVjREq2SCO-j1jI0AgrYIxF2Wv2b_RJVWz6d__NO37a5f09EJnc4sECheGCBLtOa6JRU3xyjA5_b7o8Oh_tZjw82xeS1mGtB9pFby8A=s2048?key=HUAv7i993tyJD5Ya6nycjVP_)**
		* claims to be able to measure integrated information
		* objective is to find the biggest integrated system
		* NP Complete
* Alex
	* Simple Pavlov -> Mutation & more stimuli (including neutral) -> emotions
	* Grouping of emotions from simpler to more complex
		* ![[{C75697B0-8E22-4076-AD7E-7CC6D24E685B}.png]]
	* Vector Model - an attempt at assigning numbers to and categorizing different emotions based on the 2D Map of Affective States
		* ![[{4FD2CF0F-E498-4184-BC50-85317BFF1C9E}.png]]
* Dominic
	* Artificial vs. Machine Consciousness
		* Artificial replicates conscious experience
		* Machine stresses purely mechanical imitation
	* Strong vs. Weak AC
		* Strong - systems w/ genuine phenomenal experience ("what it feels like")
		* Weak - systems w/ only access consciousness -- functional info w/o any inner experience
	* Current Approach
		* Attention-Schema Theory + Transformers
			* Same attention mechanism as powerful large LLMs
			* Higher-level "schema" that focuses attention on the inner workings of the transformer
				* Simulates self-awareness
		* Anthropomorphism Challenge
			* Even sophisticated behavior ("I feel," "I think") can be mimicry without any real subjective experience
	* Arguments
		* Against
			* Suffering Explosion
			* Misuse & Abuse
			* Rebellion Fear
		* For
			* Scientific Instrument
			* Transparent Control
			* Enhanced AI
	* Is Strong AC Possible?
		* Those who say yes lean on functionalism/information-theory 
			* Covered information theory here [[Information Theory]]
		* Skeptics argue that that requires specific quantum-chemical or biological mechanisms that computers don't have
	* Communication-Based Consciousness
		* Two-way info exchange
		* Evolutionary advantage
		* Sync requirement
		* Beyond single signals
	* LLMs quality as CBC due to
		* Internal voice
		* Internal conscious features
		* Chain of thought
		* Self/non-self distinction


How does it connect to what you learned from your own work?
* Similar to Will G's IIT the [[Picturing the Mind Consciousness Through the Lens of Evolution]] broke consciousness into 8 parts
	* IIT's integration is similar to the Global accessibility and broadcast characteristic
	* IIT's information and exclusion is loosely similar to selective exclusion and attention
	* IIT's intrinsic existence is similar to embodiment and agency
	* IIT's composition is very broad and I can see an argument for it fitting into multiple of the 8 parts 
* I believe emotions are an essential part of consciousness so even though I am hesitant to accept the vector model of emotions Alex accepted, I understand that how emotions work and how they can be represented in data is likely very essential for consciousness and, to tie to my work, the benchmark that allows for consciousness - unlimited associative learning (UAL) [[Picturing the Mind Consciousness Through the Lens of Evolution]]
	* Additionally, the Pavlov-inspired tuning is reminiscent of Active Inference [[Active Inference]] due to the way that each new stimuli presents a new likelihood, probability, of a new result, changing the weights/probabilities accordingly if you interpret it that way
* Dominic's Artificial Consciousness seems to be like the end result of everything discussed
	* Will's IIT presenting a mathematical (but really difficult and likely more of a shot in the dark) way of calculations of consciousness
	* My 8 parts of consciousness and UAL serving as requirements and benchmarks for AC
	* Active Inference serving as a potential implementation of part of AC 
	* Alex's description of emotion, stimuli, and results being something worthwhile to mimic in AC and possibly using or taking inspiration from the vector mapping to encode emotions into the AC model

What would you like to learn more about?
* What separates artificial consciousness from consciousness?
* What is the closest we have gotten to artificial consciousness?
* Can artificial consciousness cure loneliness? Can loneliness be cured? 