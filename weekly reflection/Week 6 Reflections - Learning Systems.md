What did you learn from the other student presentations on this week's topic?

* I learned about NEAT, CPPNs, and HyperNEAT from William.
* I learned what the term task-agnostic learning and further thoughts about meta-learning and the consequences of AI models from Alex.
* I learned about ANML (A Neuromodulated Meta-Learning Algorithm) and evolving neural networks to solve different problems from Dominic.

How does it connect to what you learned from your own work?

* Both Alex and Dominic's presentations talked about dealing with catastrophic forgetting, which was mentioned in the neural cellular automata with the lizard when forcibly resampling the single cell in the regeneration sample pool strategy [[Mordvinstev (2020)]] [[Week 6.pdf]]
* All the presentations dealt with ANNs in some capacity
* In terms of solving multiple problems as Dominic's second paper was focused on. Mordvinstev's lizard had to first learn how to grow for a certain number of steps (the first problem), then learn how to grow for steps beyond (second problem), regenerate (third), and rotate (fourth). [[Mordvinstev (2020)]] 
* Many of the other presentations sought to do what the early NCA [[Tavares (2015)]] wanted to do in the way of limitless emergence of complexity rather than [[Mordvinstev (2020)]] specific focus on a singular goal: creating resilient, regrowing emojis. 

What would you like to learn more about?

* I want to learn more about how to use ANNs to model human behavior and interpersonal dynamics. 